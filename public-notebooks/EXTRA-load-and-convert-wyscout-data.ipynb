{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook downloads the opensource [Soccer match event dataset](https://figshare.com/collections/Soccer_match_event_dataset/4415000/2) and converts it to the [SPADL format](https://github.com/ML-KULeuven/socceraction). This dataset contains all spatio-temporal events (passes, shots, fouls, etc.) that occured during all matches of the 2017/18 season of the top-5 European leagues (La Liga, Serie A, Bundesliga, Premier League, Ligue 1) as well as the FIFA World Cup 2018 and UEFA Euro Cup 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer**: this notebook is compatible with [v5 of the Soccer match event dataset](https://figshare.com/collections/Soccer_match_event_dataset/4415000/5) and the following package versions:\n",
    "\n",
    "- tqdm 4.42.1\n",
    "- requests 2.22.0\n",
    "- pandas 1.0\n",
    "- socceraction 0.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; import sys;\n",
    "import tqdm\n",
    "import requests\n",
    "import mimetypes\n",
    "import zipfile\n",
    "import math\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import socceraction.spadl as spadl\n",
    "import socceraction.spadl.wyscout as wyscout\n",
    "\n",
    "# Wyscout does not distinguish between headers and other body\n",
    "# parts on shots. The socceraction convertor simply labels all\n",
    "# shots as performed by foot. I think it is better to label \n",
    "# them as headers.\n",
    "def determine_bodypart_id(event):\n",
    "    \"\"\"\n",
    "    This function determines the body part used for an event\n",
    "    Args:\n",
    "    event (pd.Series): Wyscout event Series\n",
    "    Returns:\n",
    "    int: id of the body part used for the action\n",
    "    \"\"\"\n",
    "    if event[\"subtype_id\"] in [81, 36, 21, 90, 91]:\n",
    "        body_part = \"other\"\n",
    "    elif event[\"subtype_id\"] == 82 or event['head/body']:\n",
    "        body_part = \"head\"\n",
    "    else:  # all other cases\n",
    "        body_part = \"foot\"\n",
    "    return spadl.config.bodyparts.index(body_part)\n",
    "wyscout.determine_bodypart_id = determine_bodypart_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure folder names and download URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spadl_datafolder = \"../data/wyscout\"\n",
    "raw_datafolder = \"../data/wyscout/raw\"\n",
    "\n",
    "# Create data folder if it doesn't exist\n",
    "for d in [raw_datafolder, spadl_datafolder]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "        print(f\"Directory {d} created \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://figshare.com/collections/Soccer_match_event_dataset/4415000/5\n",
    "dataset_urls = dict(\n",
    "    eventid2name = \"https://ndownloader.figshare.com/files/21385245\",\n",
    "    tags2name = \"https://ndownloader.figshare.com/files/21385239\",\n",
    "    competitions = \"https://ndownloader.figshare.com/files/15073685\",\n",
    "    teams = \"https://ndownloader.figshare.com/files/15073697\",\n",
    "    coaches = \"https://ndownloader.figshare.com/files/15073868\",\n",
    "    referees = \"https://ndownloader.figshare.com/files/15074030\",\n",
    "    players = \"https://ndownloader.figshare.com/files/15073721\",\n",
    "    matches = \"https://ndownloader.figshare.com/files/14464622\",\n",
    "    events = \"https://ndownloader.figshare.com/files/14464685\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download public WyScout data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading eventid2name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1MB [00:00, 419.98MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tags2name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1MB [00:00, 397.49MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading competitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1MB [00:00, 419.77MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading teams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1MB [00:00, 40.63MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading coaches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1MB [00:00, 23.08MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading referees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1MB [00:00, 13.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading players\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2MB [00:00, 10.69MB/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading matches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1MB [00:00,  1.96MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting matches\n",
      "Downloading events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74MB [00:03, 21.59MB/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting events\n",
      "Downloaded files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['matches_Italy.json',\n",
       " 'events_Spain.json',\n",
       " 'matches_World_Cup.json',\n",
       " 'matches_Germany.json',\n",
       " 'coaches.json',\n",
       " 'eventid2name.csv',\n",
       " 'matches_European_Championship.json',\n",
       " 'events_England.json',\n",
       " 'events_France.json',\n",
       " 'teams.json',\n",
       " 'matches_England.json',\n",
       " 'events_World_Cup.json',\n",
       " 'tags2name.csv',\n",
       " 'matches_Spain.json',\n",
       " 'events_European_Championship.json',\n",
       " 'events_Italy.json',\n",
       " 'matches_France.json',\n",
       " 'events_Germany.json',\n",
       " 'players.json',\n",
       " 'competitions.json',\n",
       " 'referees.json',\n",
       " 'events.zip',\n",
       " 'matches.zip']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, url in dataset_urls.items():\n",
    "    print(f\"Downloading {key}\")\n",
    "    # Streaming, so we can iterate over the response.\n",
    "    r = requests.get(url, stream=True)\n",
    "    content_type = r.headers['content-type']\n",
    "    extension = mimetypes.guess_extension(content_type)\n",
    "\n",
    "    # Total size in bytes.\n",
    "    total_size = int(r.headers.get(\"content-length\", 0))\n",
    "    block_size = 1024 * 1024\n",
    "    wrote = 0\n",
    "    with open(f\"{raw_datafolder}/{key}{extension}\", \"wb\") as f:\n",
    "        datastream = tqdm.tqdm(\n",
    "            r.iter_content(block_size),\n",
    "            total=math.ceil(total_size // block_size),\n",
    "            unit=\"MB\",\n",
    "            #unit_scale=True,\n",
    "            #unit_divisor=1024\n",
    "        )\n",
    "        for data in datastream:\n",
    "            wrote = wrote + len(data)\n",
    "            f.write(data)\n",
    "    if extension == \".zip\":\n",
    "        print(f\"Extracting {key}\")\n",
    "        with zipfile.ZipFile(f\"{raw_datafolder}/{key}.zip\", 'r') as zipObj:\n",
    "            zipObj.extractall(f\"{raw_datafolder}\")\n",
    "    if total_size != 0 and wrote != total_size:\n",
    "        print(\"ERROR, something went wrong\")\n",
    "\n",
    "print(\"Downloaded files:\")\n",
    "os.listdir(raw_datafolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select competitions to load and convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'England',\n",
       " 'European Championship',\n",
       " 'France',\n",
       " 'Germany',\n",
       " 'Italy',\n",
       " 'Spain',\n",
       " 'World Cup'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competitions = pd.read_json(f\"{raw_datafolder}/competitions.json\")\n",
    "# Rename competitions to the names used in the file names\n",
    "competitions['name'] = competitions.apply(lambda x: x.area['name'] if x.area['name'] != \"\" else x['name'], axis=1)\n",
    "# View all available competitions\n",
    "set(competitions.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>wyId</th>\n",
       "      <th>format</th>\n",
       "      <th>area</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>364</td>\n",
       "      <td>Domestic league</td>\n",
       "      <td>{'name': 'England', 'id': '0', 'alpha3code': '...</td>\n",
       "      <td>club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  wyId           format  \\\n",
       "1  England   364  Domestic league   \n",
       "\n",
       "                                                area  type  \n",
       "1  {'name': 'England', 'id': '0', 'alpha3code': '...  club  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Domestic leagues\n",
    "#selected_competitions = competitions[competitions.name.isin(\n",
    "#    [\"England\", \"France\", \"Germany\", \"Italy\", \"Spain\"]\n",
    "#)]\n",
    "\n",
    "# Premier leagues\n",
    "selected_competitions = competitions[competitions.name == \"England\"]\n",
    "\n",
    "# International\n",
    "#selected_competitions = competitions[competitions.name.isin(\n",
    "#    ['European Championship', 'World Cup']\n",
    "#)]\n",
    "\n",
    "selected_competitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and convert match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing England\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [07:00<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "player_games = []\n",
    "actions = {}\n",
    "for row in selected_competitions.itertuples():\n",
    "    print(f\"Processing {row.name}\")\n",
    "    # load data\n",
    "    matches = pd.read_json(f\"{raw_datafolder}/matches_{row.name}.json\")\n",
    "    events = pd.read_json(f\"{raw_datafolder}/events_{row.name}.json\").groupby('matchId', as_index=False)\n",
    "    for match in tqdm.tqdm(list(matches.itertuples())):\n",
    "        match_id = match.wyId\n",
    "        match_events = events.get_group(match_id)\n",
    "\n",
    "        # convert data\n",
    "        player_games.append(wyscout.get_player_games(match, match_events))\n",
    "        home_team = next(filter(lambda x: x['side'] == 'home', match.teamsData.values()))['teamId']\n",
    "        actions[match_id] = wyscout.convert_actions(match_events, home_team)\n",
    "        # action id is missing !\n",
    "        actions[match_id][\"action_id\"] = range(len(actions[match_id]))\n",
    "\n",
    "player_games = pd.concat(player_games).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store converted SPADL data in a HDF-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pieterr/Jupiter/Projects/soccer_dataprovider_comparison/.venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3331: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['name', 'format', 'area', 'type'], dtype='object')]\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "spadl_h5 = os.path.join(spadl_datafolder, \"spadl-wyscout.h5\")\n",
    "\n",
    "# Store all spadl data in h5-file\n",
    "with pd.HDFStore(spadl_h5) as spadlstore:\n",
    "    spadlstore[\"competitions\"] = selected_competitions\n",
    "    matches = pd.concat(list(\n",
    "        pd.read_json(f\"{raw_datafolder}/matches_{row.name}.json\")\n",
    "        for row in selected_competitions.itertuples()\n",
    "    ))\n",
    "    spadlstore[\"games\"] = wyscout.convert_games(matches)\n",
    "    players = wyscout.convert_players(pd.read_json(f\"{raw_datafolder}/players.json\"))\n",
    "    spadlstore[\"players\"] = players\n",
    "    spadlstore[\"teams\"] = wyscout.convert_teams(pd.read_json(f\"{raw_datafolder}/teams.json\"))\n",
    "    for game_id in actions.keys():\n",
    "        spadlstore[f\"actions/game_{game_id}\"] = actions[game_id]\n",
    "        \n",
    "    spadlstore[\"actiontypes\"] = spadl.actiontypes_df()\n",
    "    spadlstore[\"results\"] = spadl.results_df()\n",
    "    spadlstore[\"bodyparts\"] = spadl.bodyparts_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soccer_dataprovider_comparison",
   "language": "python",
   "name": "soccer_dataprovider_comparison"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
